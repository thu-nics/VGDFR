{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')\n",
    "if not os.path.exists('VGDFR'):\n",
    "    os.chdir('../')\n",
    "# print current work dir\n",
    "print(os.getcwd())\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from hyvideo.vae.autoencoder_kl_causal_3d import AutoencoderKLCausal3D\n",
    "from hyvideo.vae import load_vae\n",
    "from hyvideo.utils.file_utils import save_videos_grid\n",
    "from hyvideo.inference import HunyuanVideoSampler\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "from hyvideo.config import *\n",
    "from VGDFR.hunyuan_vgdfr import VGDFRHunyuanVideoSampler,mod_rope_forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_args=\"\"\"--video-size 544 960 --video-length 65 --infer-steps 50 --prompt cat. --flow-reverse --use-cpu-offload --save-path ./results --seed 3\"\"\"\n",
    "string_args=string_args.split(\" \")\n",
    "print(string_args)\n",
    "\n",
    "def parse_args_new(namespace=None,string_args=None):\n",
    "    parser = argparse.ArgumentParser(description=\"HunyuanVideo inference script\")\n",
    "\n",
    "    parser = add_network_args(parser)\n",
    "    parser = add_extra_models_args(parser)\n",
    "    parser = add_denoise_schedule_args(parser)\n",
    "    parser = add_inference_args(parser)\n",
    "    parser = add_parallel_args(parser)\n",
    "\n",
    "    args = parser.parse_args(string_args,namespace=namespace)\n",
    "    args = sanity_check_args(args)\n",
    "\n",
    "    return args\n",
    "\n",
    "args = parse_args_new(string_args=string_args)\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_root_path = Path(args.model_base)\n",
    "hunyuan_video_sampler = VGDFRHunyuanVideoSampler.from_pretrained(models_root_path, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 27/45 [00:23<00:15,  1.17it/s]"
     ]
    }
   ],
   "source": [
    "seed = 3\n",
    "args.infer_steps = 50\n",
    "width, height = 960, 544\n",
    "width, height = 500, 344\n",
    "video_length = 97\n",
    "prompt=\"A spirited individual rides a vintage bicycle along a sunlit, tree-lined path, wearing a casual outfit of a white t-shirt, denim shorts, and sneakers. The scene captures the golden hour, with sunlight filtering through the leaves, casting dappled shadows on the ground. The rider's hair flows freely in the breeze, and a joyful smile lights up their face. As they pedal, the camera zooms in to reveal the intricate details of the bike's design, including its classic handlebars and shiny bell. The background features a serene park with blooming flowers and a distant lake, enhancing the sense of freedom and tranquility.\"\n",
    "for before_compression_steps in [5, 10, 15]:\n",
    "    hunyuan_video_sampler.pipeline.before_compression_steps = before_compression_steps\n",
    "    for similarity_threshold in [0.6, 0.7, 0.8, 0.9]:\n",
    "        hunyuan_video_sampler.pipeline.similarity_threshold = similarity_threshold\n",
    "\n",
    "        samples = hunyuan_video_sampler.predict(\n",
    "            prompt=prompt,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            video_length=video_length,\n",
    "            seed=seed,\n",
    "            negative_prompt=args.neg_prompt,\n",
    "            infer_steps=args.infer_steps,\n",
    "            guidance_scale=args.cfg_scale,\n",
    "            num_videos_per_prompt=args.num_videos,\n",
    "            flow_shift=args.flow_shift,\n",
    "            batch_size=args.batch_size,\n",
    "            embedded_guidance_scale=args.embedded_cfg_scale,\n",
    "        )[\"samples\"]\n",
    "        save_path = args.save_path\n",
    "        # log_dlfr_t = hunyuan_video_sampler.pipeline.log_dlfr_t\n",
    "        # Save samples\n",
    "        if \"LOCAL_RANK\" not in os.environ or int(os.environ[\"LOCAL_RANK\"]) == 0:\n",
    "            for i, sample in enumerate(samples):\n",
    "                sample = samples[i].unsqueeze(0)\n",
    "                time_flag = datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "                file_name = f\"raw_seed{seed}_{prompt[:100].replace('/','')}\"\n",
    "                raw_save_path = (\n",
    "                    f\"{save_path}/example/th_{similarity_threshold}_k{before_compression_steps}/{file_name}.mp4\"\n",
    "                )\n",
    "                save_videos_grid(sample, raw_save_path, fps=12)\n",
    "                torch.save(\n",
    "                    sample,\n",
    "                    f\"{save_path}/example/th_{similarity_threshold}_k{before_compression_steps}/{file_name}.pt\",\n",
    "                )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgdfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
